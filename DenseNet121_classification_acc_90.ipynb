{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_classification_acc_90.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EaFXwjAEP2yx8W147HdTmW7as9yjuNcH",
      "authorship_tag": "ABX9TyNfLl3zZ/koInwYTgTc0k7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amasnaoui/Classification_damaged_not_damaged_car/blob/main/DenseNet121_classification_acc_90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debzwsxFQLy8"
      },
      "outputs": [],
      "source": [
        "#import necessary librabry\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the base, train and validation directory path\n",
        "base_dir = '/content/drive/MyDrive/new_cars_dataset/'\n",
        "train_dir = os.path.join(base_dir, 'training')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "metadata": {
        "id": "cnyDll9GQXhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the damage and whole , train, validation and test directory\n",
        "train_damage_dir = os.path.join(train_dir, '00-damage')\n",
        "train_whole_dir = os.path.join(train_dir, '01-whole')\n",
        "validation_damage_dir = os.path.join(validation_dir, '00-damage')\n",
        "validation_whole_dir = os.path.join(validation_dir, '01-whole')\n",
        "test_damage_dir = os.path.join(test_dir, '00-damage')\n",
        "test_whole_dir = os.path.join(test_dir, '01-whole')"
      ],
      "metadata": {
        "id": "puUoaiVbQq4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range = 40,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  horizontal_flip = True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "testt_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "dYFXilodQ5pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(150, 150), \n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "testt_generator = testt_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "8HEyqkLRQ8_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining model\n",
        "from tensorflow.keras import Model \n",
        "from tensorflow.keras.applications import DenseNet121   \n",
        "\n",
        "base_model = DenseNet121(input_shape = (150, 150, 3),  include_top = False, weights = 'imagenet') "
      ],
      "metadata": {
        "id": "2s83-36JRTLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=   tf.keras.layers.Flatten()(base_model.output)\n",
        "x=   tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x=   tf.keras.layers.Dense(1, activation='sigmoid')(x) \n",
        "\n",
        "model= Model(base_model.input, x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['Accuracy','Precision','Recall'])"
      ],
      "metadata": {
        "id": "fqeJ_9aYRgdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=15,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=1)"
      ],
      "metadata": {
        "id": "08P4c8oERjsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['Accuracy']\n",
        "val_acc = history.history['val_Accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aiiaL8VM75la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['precision']\n",
        "val_acc = history.history['val_precision']\n",
        "loss = history.history['recall']\n",
        "val_loss = history.history['val_recall']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CXNyVeth7-IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(testt_generator, verbose = 1)\n",
        "print(\"Accuracy : %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "mDNaynfYRrYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#weights saving\n",
        "model.save(\"/content/drive/MyDrive/new_cars_dataset/models/DenseNet121_classifier_90%.h5\")"
      ],
      "metadata": {
        "id": "T3Wjj9N_3ESc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "new_model = load_model(\"/content/drive/MyDrive/new_cars_dataset/DenseNet121_classifier_89%.h5\")"
      ],
      "metadata": {
        "id": "gxBISQZF4Qzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/clean data/scrap_didier.be/'\n",
        "\n",
        "j = 0\n",
        "for sub_dir in os.listdir(dir_path):\n",
        "  if j < 4:\n",
        "    for i in os.listdir(dir_path + sub_dir):\n",
        "      img = image.load_img(dir_path + sub_dir + '//' + i, target_size=(150,150))\n",
        "      plt.imshow(img)\n",
        "      plt.show()\n",
        "\n",
        "      X = image.img_to_array(img)\n",
        "      X = np.expand_dims(X,axis=0)\n",
        "      images = np.vstack([X])\n",
        "      val = model.predict(images)\n",
        "      if (val == 0).any() :\n",
        "        print(\"damaged car\")\n",
        "      else :\n",
        "        print(\"Not damaged car\")\n",
        "    j += 1"
      ],
      "metadata": {
        "id": "2hUcKSmTQioB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "htpkK2HjR0fT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}